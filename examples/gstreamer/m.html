<!doctype html>
<!--
Copyright 2018 The Immersive Web Community Group

Permission is hereby granted, free of charge, to any person obtaining a copy of
this software and associated documentation files (the "Software"), to deal in
the Software without restriction, including without limitation the rights to
use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
the Software, and to permit persons to whom the Software is furnished to do so,
subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
-->
<html>
  <head>
    <meta charset='utf-8'>
    <meta name='viewport' content='width=device-width, initial-scale=1, user-scalable=no'>
    <meta name='mobile-web-app-capable' content='yes'>
    <meta name='apple-mobile-web-app-capable' content='yes'>
    <link rel='icon' type='image/png' sizes='32x32' href='favicon-32x32.png'>
    <link rel='icon' type='image/png' sizes='96x96' href='favicon-96x96.png'>
    <link rel='stylesheet' href='css/common.css'>

    <title>Avatar Operator Interface</title>
  </head>
  <body>
    <header>
      <details open>
        <summary>Avatar Operator Interface</summary>
        <p>
          Immersively view your avatar stereo video feed.
          <hr/>
          Autoplay when VR starts: <input id='autoplayVideo' type='checkbox' checked/>
        </p>
          <p>
            <input id='vertFOV' value='90' min='30' max='150' step='10' type='range'/><br/>
            <label id='vertFOVLabel' for="vertFOV">Vertical FOV: </label>
          </p>
      </summary>
    </header>
    <script type="module">
      import {WebXRButton} from './js/util/webxr-button.js';
      import {Scene} from './js/render/scenes/scene.js';
      import {Renderer, createWebGLContext} from './js/render/core/renderer.js';
      import {UrlTexture} from './js/render/core/texture.js';
      import {ButtonNode} from './js/render/nodes/button.js';
      import {Gltf2Node} from './js/render/nodes/gltf2.js';
      import {VideoNode} from './js/render/nodes/videoreverse.js';
      import {InlineViewerHelper} from './js/util/inline-viewer-helper.js';
      import {QueryArgs} from './js/util/query-args.js';
      import {vec3, mat3, mat4} from './js/render/math/gl-matrix.js';

      // If requested, use the polyfill to provide support for mobile devices
      // and devices which only support WebVR.
      // import WebXRPolyfill from './js/third-party/webxr-polyfill/build/webxr-polyfill.module.js';
      // if (QueryArgs.getBool('usePolyfill', true)) {
      // let polyfill = new WebXRPolyfill();
      // }

      let inlineSession = null;
      let fov = document.getElementById('vertFOV');
      let fovLabel = document.getElementById('vertFOVLabel');
      function updateFov() {
        let value = parseFloat(fov.value);
        // The inlineVerticalFieldOfView is specified in radians.
        let radValue = value * (Math.PI / 180);

        if (inlineSession) {
          // As with any values set with updateRenderState, this will take
          // effect on the next frame.
          inlineSession.updateRenderState({
            inlineVerticalFieldOfView: radValue
          });
        }
        
        // Set the label on the page
        let label = `Vertical FOV: ${value} degrees`;
        if (value == 90) {
          label += ' (default)';
        }
        fovLabel.textContent = label;
      }
      fov.addEventListener('change', updateFov);


      let autoplayCheckbox = document.getElementById('autoplayVideo');

      // XR globals.
      let xrButton = null;
      let xrImmersiveRefSpace = null;
      let inlineViewerHelper = null;

      // WebGL scene globals.
      let gl = null;
      let renderer = null;
      let scene = new Scene();
      // scene.addNode(new Gltf2Node({url: 'media/gltf/home-theater/home-theater.gltf'}));
      scene.enableStats(false);

      let video = document.createElement('video');
      video.loop = true;
      // video.id = 'video';
      video.src = 'cdshort.mp4';
      // video.src = 'media/video/bbb-sunflower-540p2-1min.webm';

      let videoNode = new VideoNode({
        video: video,
        displayMode: 'mono' // 'stereoTopBottom'
      });

      // When the video is clicked we'll pause it if it's playing.
      videoNode.onSelect(() => {
        if (!video.paused) {
          playButton.visible = true;
          video.pause();
        } else {
          playButton.visible = false;
      video.play().then(() => {
            console.log(`Video play actually started.`);
      });;
        }
      });
      videoNode.selectable = true;

      // Move back to the position of the in-room screen and size to cover it.
      // Values determined experimentally and with many refreshes.
      // videoNode.translation = [0.025, 0.275, -4.4];
      // videoNode.scale = [2.1, 1.1, 1.0];
      videoNode.translation = [0, 0.7, -1.5];
      videoNode.scale = [1, 1, 1.0];
      scene.addNode(videoNode);
      initVideo(video);

      video.addEventListener('loadeddata', () => {
        // Once the video has loaded up adjust the aspect ratio of the "screen"
        // to fit the video's native shape.
        let aspect = videoNode.aspectRatio;
        if (aspect < 2.0) {
          videoNode.scale = [aspect * 1, 1, 1.0];
        } else {
          // videoNode.scale = [2.1, 2.1 / aspect, 1.0];
          videoNode.scale = [1, 1 / aspect, 1.0];
        }
        videoNode.rotation = [0, 0, 0, 0];
      });

      // Add a button to the scene to play/pause the movie.
      let playTexture = new UrlTexture('media/textures/play-button.png');

      // Create a button that plays the video when clicked.
      let playButton = new ButtonNode(playTexture, () => {
        // Play the video and hide the button.
        if (video.paused) {
          playButton.visible = false;
        video.play().then(() => {
	console.log(`Video play actually started.`);
	});
        }
      });
      // Move the play button to the center of the screen and make it much
      // bigger.
	// playButton.translation = [0.025, 0.275, -4.2];
      // playButton.scale = [5.0, 5.0, 5.0];
      playButton.translation = [0.1, 0.57, -1.95];
      playButton.scale = [4.0, 4.0, 4.0];
      scene.addNode(playButton);

      function initXR() {
        xrButton = new WebXRButton({
          onRequestSession: onRequestSession,
          onEndSession: onEndSession
        });
        document.querySelector('header').appendChild(xrButton.domElement);

        if (navigator.xr) {
          navigator.xr.isSessionSupported('immersive-vr').then((supported) => {
            xrButton.enabled = supported;
          });

          navigator.xr.requestSession('inline').then((session) => {
            inlineSession = session;
            onSessionStarted(session);
            updateFov();
          });
        }
      }

      function initGL() {
        if (gl)
          return;

        gl = createWebGLContext({
          xrCompatible: true
        });
        document.body.appendChild(gl.canvas);

        function onResize() {
          gl.canvas.width = gl.canvas.clientWidth * window.devicePixelRatio;
          gl.canvas.height = gl.canvas.clientHeight * window.devicePixelRatio;
        }
        window.addEventListener('resize', onResize);
        onResize();

        renderer = new Renderer(gl);
        scene.setRenderer(renderer);
      }

      function onRequestSession() {
        let autoplay = autoplayCheckbox.checked;

        let pending;

        if (autoplay) {
          playButton.visible = false;
          // If we want the video to autoplay when the session has fully started
          // (which may be several seconds after the original requestSession
          // call due to clicking through consent prompts or similar) then we
          // need to start the video within a user activation event first
          // (which this function is.) Once it's been started successfully we
          // pause it, at which point we can resume it pretty much whenever we'd
          // like.
          pending = video.play().then(() => {
            console.log(`Video play actually started.`);
            video.pause();
          });
        }

        return navigator.xr.requestSession('immersive-vr', {
            requiredFeatures: ['local-floor']
        }).then((session) => {
          xrButton.setSession(session);
          session.isImmersive = true;
          onSessionStarted(session);

          if (autoplay) {
            pending.then(() => {
        video.play().then(() => {
            console.log(`Video play actually started.`);
	});
            });
          }
        });
      }

      function onSessionStarted(session) {
        session.addEventListener('end', onSessionEnded);
        session.addEventListener('select', (ev) => {
          let refSpace = ev.frame.session.isImmersive ?
                           xrImmersiveRefSpace :
                           inlineViewerHelper.referenceSpace;
          scene.handleSelect(ev.inputSource, ev.frame, refSpace);
        });

        initGL();
        scene.inputRenderer.useProfileControllerMeshes(session);

        let glLayer = new XRWebGLLayer(session, gl);
        session.updateRenderState({ baseLayer: glLayer });

        // In this case we're going to use an 'local' frame of reference
        // because we want to users head to appear in the right place relative
        // to the center chair, as if they're sitting in it, rather than
        // somewhere in the room relative to the floor.
        let refSpaceType = session.isImmersive ? 'local' : 'viewer';
        session.requestReferenceSpace(refSpaceType).then((refSpace) => {
          if (session.isImmersive) {
            xrImmersiveRefSpace = refSpace;
          } else {
            inlineViewerHelper = new InlineViewerHelper(gl.canvas, refSpace);
          }

          session.requestAnimationFrame(onXRFrame);
        });
      }

      function onEndSession(session) {
        session.end();
      }

      function onSessionEnded(event) {
        if (event.session.isImmersive) {
          xrButton.setSession(null);
          video.pause();
        }
      }

	function fixPosition() {
          xrSession.requestReferenceSpace("viewer")
	    .then((refSpace) => {
	    xrReferenceSpace = refSpace;
	    xrReferenceSpace = xrReferenceSpace.getOffsetReferenceSpace(
              new XRRigidTransform(startPosition, {x:0, y:0, z:1.0, w: 1.0}));
            
            xrSession.requestAnimationFrame(drawFrame);
	  });
	}

      function onXRFrame(t, frame) {
        let session = frame.session;
        let refSpace = session.isImmersive ?
                         xrImmersiveRefSpace :
                         inlineViewerHelper.referenceSpace;

        scene.startFrame();

        let pose = frame.getViewerPose(refSpace);
        let rot = pose.transform.orientation;
        let pos = pose.transform.position;
        let [x, y, z, w] = [pos.x, pos.y, pos.z, pos.w];
	let rx = rot.x * 2.5; // Math.PI;
	let ry = rot.y * 2.5; // Math.PI;
	let rz = rot.z * 2.5; // Math.PI;
	let [vx, vy, vz] = [0.15, 0.7, -1.5];
	let nx = vx * Math.cos(-ry) - vz * Math.sin(-ry);
	let nz = vx * Math.sin(-ry) + vz * Math.cos(-ry);
	let ny = vy;
	// let ny = vy * Math.cos(rx) - vz * Math.sin(rx);
	// nz = vy * Math.sin(rx) - vz * Math.sin(rx);
	// console.log(`rot.x: ${rot.x}, ry: ${ry}, rot.z: ${rot.z}, nx: ${nx}, nz: ${nz}`);
        videoNode.translation = [nx, ny, nz, 0];
	videoNode.rotation = [rot.x, rot.y, rot.z, rot.w];

        session.requestAnimationFrame(onXRFrame);

        scene.updateInputSources(frame, refSpace);

        scene.drawXRFrame(frame, pose);

        scene.endFrame();
      }

      // Start the XR application.
      initXR();

    function initVideo(videoElement) {
      function jsonRpc(payload, cb) {
	console.log(`jsonRpc called:`, payload);
        var xhttp = new XMLHttpRequest();
        xhttp.onreadystatechange = function(data) {
	  console.log(`RPS response`, data);
          if (this.readyState == 4 && this.status == 200) {
            cb(this.responseText);
          }
        };
        xhttp.open('POST', '/api');
        xhttp.setRequestHeader('Content-Type', 'application/json');
        xhttp.send(JSON.stringify(payload));
      }
      let pc = new RTCPeerConnection({
        rtcpMuxPolicy: 'require', bundlePolicy: 'max-bundle',
        iceServers: [{urls: 'stun:w5.lig.net:3478'}],
        iceServersHide: [{urls: 'stun:w5.lig.net:3478'}, {urls: 'stun:lig.net:3478'}, {urls: 'turn:w5.lig.net:3478', username: 'forged', credential: 'droids'}, {urls: 'turn:lig.net:3478', username: 'forged', credential: 'droids'}]
      });
      let log = msg => {
        console.log(msg);
      };

      pc.ontrack = function (event) {
        console.log(`ontrack: Playing`);
        // var el = document.getElementById('video');
        var el = videoElement; // document.getElementById('video');
        el.srcObject = event.streams[0];
        el.id = event.streams[0].id;
	// el.id = 'video';
        el.autoplay = true;
        el.controls = true;
        el.muted = true;
	el.playsinline = true;
	el.webkitPlaysinline = true;
        el.addEventListener("click", function() { el.play(); });
	el.onloadedmetadataHide = () => { el.play().then(() => {
            console.log(`Video play actually started.`);
	});
	};
	// el.webkitPlaysinline = true;
        // el.addEventListener("click", function() { el.play(); });
      };

      pc.oniceconnectionstatechange = e => log(pc.iceConnectionState);
      function jsonRpcHandle(result) {
        let sdp = JSON.parse(result).result;
        if (sdp === '') {
          return alert('Session Description must not be empty');
        }
        try {
          let sdps = JSON.parse(atob(sdp));
          console.log(`SDP:`, sdps);
          pc.setRemoteDescription(new RTCSessionDescription(sdps));
        } catch (e) {
          alert(e);
        }
      }
      pc.onicecandidate = event => {
        if (event.candidate === null) {
	console.log(event);
          var lines = pc.localDescription.sdp.split('\n');
          for(let i = 0; i < lines.length; i++) {
            // remove candidate which libnice cannot parse.
            if (lines[i].search('candidate') != -1 && lines[i].search('local') != -1) {
              lines.splice(i, 1);
              i--;
            }
          }
          let sdp = lines.join('\n');
	  console.log(`Sending SDP: ${sdp}`);
          var payload = {"jsonrpc": "2.0", "method": "call", "params": btoa(sdp)};
          jsonRpc(payload, jsonRpcHandle);
        }
      };
      pc.addTransceiver('video', {'direction': 'sendrecv'})
      let options = {
        offerToReceiveVideo: true,
        offerToReceiveAudio: true,
      };
      pc.createOffer().then(d => {
        console.log(`createOffser:`, d);
        pc.setLocalDescription(d);
      }).catch(log);
      window.startSession = () => {
        let sd = document.getElementById('remoteSessionDescription').value;
      }
    };
    </script>
  </body>
</html>
